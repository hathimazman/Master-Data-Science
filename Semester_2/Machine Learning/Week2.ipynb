{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Used to predict quantitative (numerical) response.\n",
    "+ Can we determine if a relationship exists between predictors and response?\n",
    "+ How strong is this relationship?\n",
    "+ Which predictors are related to response?\n",
    "+ How accurate are predictions once model is fit?\n",
    "+ Is a linear model appropriate?\n",
    "+ Are there interaction effects?\n",
    "\n",
    "## Simple Linear Regression (SLR)\n",
    "Technically this means one predictor is linearly related to the response.\n",
    "\t$$ Y = \\beta_0 +  \\beta_1 X + \\epsilon$$\n",
    "\n",
    "There are two unknown constants that we need to estimate, the intercept $\\beta_0$ and the slope, $\\beta_1$. Also called coefficients or parameters. \n",
    "\t\n",
    "Once they are estimated, the estimated fit becomes \n",
    "\t$$ \\hat{Y} = \\hat{\\beta_0} +  \\hat{\\beta_1} X$$\n",
    "\n",
    "There are various ways of estimating the coefficients. The most common approach is via the **least squares technique**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Radio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Newspaper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e14c2732-ef75-4f1c-acb5-c0cd2e83ecf6",
       "rows": [
        [
         "0",
         "230.1",
         "37.8",
         "69.2",
         "22.1"
        ],
        [
         "1",
         "44.5",
         "39.3",
         "45.1",
         "10.4"
        ],
        [
         "2",
         "17.2",
         "45.9",
         "69.3",
         "9.3"
        ],
        [
         "3",
         "151.5",
         "41.3",
         "58.5",
         "18.5"
        ],
        [
         "4",
         "180.8",
         "10.8",
         "58.4",
         "12.9"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv = pd.read_csv('data/Advertising.csv')\n",
    "adv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = np.polyfit(adv['TV'], adv['Sales'], deg=1)\n",
    "y_hat = fit[1] + adv['TV'] * fit[0]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x='TV', y='Sales', data=adv)\n",
    "plt.vlines(adv['TV'], y_hat, adv['Sales'], lw = .4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m       \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCall signature:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mType:\u001b[0m            _ArrayFunctionDispatcher\n",
      "\u001b[1;31mString form:\u001b[0m     <function polyfit at 0x000002243333E3B0>\n",
      "\u001b[1;31mFile:\u001b[0m            c:\\users\\hathim\\anaconda3\\envs\\msc3.10\\lib\\site-packages\\numpy\\lib\\_polynomial_impl.py\n",
      "\u001b[1;31mDocstring:\u001b[0m      \n",
      "Least squares polynomial fit.\n",
      "\n",
      ".. note::\n",
      "   This forms part of the old polynomial API. Since version 1.4, the\n",
      "   new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "   A summary of the differences can be found in the\n",
      "   :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\n",
      "to points `(x, y)`. Returns a vector of coefficients `p` that minimises\n",
      "the squared error in the order `deg`, `deg-1`, ... `0`.\n",
      "\n",
      "The `Polynomial.fit <numpy.polynomial.polynomial.Polynomial.fit>` class\n",
      "method is recommended for new code as it is more stable numerically. See\n",
      "the documentation of the method for more information.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : array_like, shape (M,)\n",
      "    x-coordinates of the M sample points ``(x[i], y[i])``.\n",
      "y : array_like, shape (M,) or (M, K)\n",
      "    y-coordinates of the sample points. Several data sets of sample\n",
      "    points sharing the same x-coordinates can be fitted at once by\n",
      "    passing in a 2D-array that contains one dataset per column.\n",
      "deg : int\n",
      "    Degree of the fitting polynomial\n",
      "rcond : float, optional\n",
      "    Relative condition number of the fit. Singular values smaller than\n",
      "    this relative to the largest singular value will be ignored. The\n",
      "    default value is len(x)*eps, where eps is the relative precision of\n",
      "    the float type, about 2e-16 in most cases.\n",
      "full : bool, optional\n",
      "    Switch determining nature of return value. When it is False (the\n",
      "    default) just the coefficients are returned, when True diagnostic\n",
      "    information from the singular value decomposition is also returned.\n",
      "w : array_like, shape (M,), optional\n",
      "    Weights. If not None, the weight ``w[i]`` applies to the unsquared\n",
      "    residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are\n",
      "    chosen so that the errors of the products ``w[i]*y[i]`` all have the\n",
      "    same variance.  When using inverse-variance weighting, use\n",
      "    ``w[i] = 1/sigma(y[i])``.  The default value is None.\n",
      "cov : bool or str, optional\n",
      "    If given and not `False`, return not just the estimate but also its\n",
      "    covariance matrix. By default, the covariance are scaled by\n",
      "    chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed\n",
      "    to be unreliable except in a relative sense and everything is scaled\n",
      "    such that the reduced chi2 is unity. This scaling is omitted if\n",
      "    ``cov='unscaled'``, as is relevant for the case that the weights are\n",
      "    w = 1/sigma, with sigma known to be a reliable estimate of the\n",
      "    uncertainty.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "p : ndarray, shape (deg + 1,) or (deg + 1, K)\n",
      "    Polynomial coefficients, highest power first.  If `y` was 2-D, the\n",
      "    coefficients for `k`-th data set are in ``p[:,k]``.\n",
      "\n",
      "residuals, rank, singular_values, rcond\n",
      "    These values are only returned if ``full == True``\n",
      "\n",
      "    - residuals -- sum of squared residuals of the least squares fit\n",
      "    - rank -- the effective rank of the scaled Vandermonde\n",
      "       coefficient matrix\n",
      "    - singular_values -- singular values of the scaled Vandermonde\n",
      "       coefficient matrix\n",
      "    - rcond -- value of `rcond`.\n",
      "\n",
      "    For more details, see `numpy.linalg.lstsq`.\n",
      "\n",
      "V : ndarray, shape (deg + 1, deg + 1) or (deg + 1, deg + 1, K)\n",
      "    Present only if ``full == False`` and ``cov == True``.  The covariance\n",
      "    matrix of the polynomial coefficient estimates.  The diagonal of\n",
      "    this matrix are the variance estimates for each coefficient.  If y\n",
      "    is a 2-D array, then the covariance matrix for the `k`-th data set\n",
      "    are in ``V[:,:,k]``\n",
      "\n",
      "\n",
      "Warns\n",
      "-----\n",
      "RankWarning\n",
      "    The rank of the coefficient matrix in the least-squares fit is\n",
      "    deficient. The warning is only raised if ``full == False``.\n",
      "\n",
      "    The warnings can be turned off by\n",
      "\n",
      "    >>> import warnings\n",
      "    >>> warnings.simplefilter('ignore', np.exceptions.RankWarning)\n",
      "\n",
      "See Also\n",
      "--------\n",
      "polyval : Compute polynomial values.\n",
      "linalg.lstsq : Computes a least-squares fit.\n",
      "scipy.interpolate.UnivariateSpline : Computes spline fits.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The solution minimizes the squared error\n",
      "\n",
      ".. math::\n",
      "    E = \\sum_{j=0}^k |p(x_j) - y_j|^2\n",
      "\n",
      "in the equations::\n",
      "\n",
      "    x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
      "    x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n",
      "    ...\n",
      "    x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\n",
      "\n",
      "The coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n",
      "\n",
      "`polyfit` issues a `~exceptions.RankWarning` when the least-squares fit is\n",
      "badly conditioned. This implies that the best fit is not well-defined due\n",
      "to numerical error. The results may be improved by lowering the polynomial\n",
      "degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\n",
      "can also be set to a value smaller than its default, but the resulting\n",
      "fit may be spurious: including contributions from the small singular\n",
      "values can add numerical noise to the result.\n",
      "\n",
      "Note that fitting polynomial coefficients is inherently badly conditioned\n",
      "when the degree of the polynomial is large or the interval of sample points\n",
      "is badly centered. The quality of the fit should always be checked in these\n",
      "cases. When polynomial fits are not satisfactory, splines may be a good\n",
      "alternative.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Wikipedia, \"Curve fitting\",\n",
      "       https://en.wikipedia.org/wiki/Curve_fitting\n",
      ".. [2] Wikipedia, \"Polynomial interpolation\",\n",
      "       https://en.wikipedia.org/wiki/Polynomial_interpolation\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> import warnings\n",
      ">>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
      ">>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
      ">>> z = np.polyfit(x, y, 3)\n",
      ">>> z\n",
      "array([ 0.08703704, -0.81349206,  1.69312169, -0.03968254]) # may vary\n",
      "\n",
      "It is convenient to use `poly1d` objects for dealing with polynomials:\n",
      "\n",
      ">>> p = np.poly1d(z)\n",
      ">>> p(0.5)\n",
      "0.6143849206349179 # may vary\n",
      ">>> p(3.5)\n",
      "-0.34732142857143039 # may vary\n",
      ">>> p(10)\n",
      "22.579365079365115 # may vary\n",
      "\n",
      "High-order polynomials may oscillate wildly:\n",
      "\n",
      ">>> with warnings.catch_warnings():\n",
      "...     warnings.simplefilter('ignore', np.exceptions.RankWarning)\n",
      "...     p30 = np.poly1d(np.polyfit(x, y, 30))\n",
      "...\n",
      ">>> p30(4)\n",
      "-0.80000000000000204 # may vary\n",
      ">>> p30(5)\n",
      "-0.99999999999999445 # may vary\n",
      ">>> p30(4.5)\n",
      "-0.10547061179440398 # may vary\n",
      "\n",
      "Illustration:\n",
      "\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> xp = np.linspace(-2, 6, 100)\n",
      ">>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n",
      ">>> plt.ylim(-2,2)\n",
      "(-2, 2)\n",
      ">>> plt.show()\n",
      "\u001b[1;31mClass docstring:\u001b[0m\n",
      "Class to wrap functions with checks for __array_function__ overrides.\n",
      "\n",
      "All arguments are required, and can only be passed by position.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "dispatcher : function or None\n",
      "    The dispatcher function that returns a single sequence-like object\n",
      "    of all arguments relevant.  It must have the same signature (except\n",
      "    the default values) as the actual implementation.\n",
      "    If ``None``, this is a ``like=`` dispatcher and the\n",
      "    ``_ArrayFunctionDispatcher`` must be called with ``like`` as the\n",
      "    first (additional and positional) argument.\n",
      "implementation : function\n",
      "    Function that implements the operation on NumPy arrays without\n",
      "    overrides.  Arguments passed calling the ``_ArrayFunctionDispatcher``\n",
      "    will be forwarded to this (and the ``dispatcher``) as if using\n",
      "    ``*args, **kwargs``.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "_implementation : function\n",
      "    The original implementation passed in."
     ]
    }
   ],
   "source": [
    "np.polyfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04753664, 7.03259355])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Accuracy of the Coefficient Estimates\n",
    "The theoretical best linear relationship can be defined as: \n",
    "\t$$Y = \\beta_0 + \\beta_1 X + \\epsilon$$\n",
    "\n",
    "This **population regression line** will never be known in practice and remain unobserved unless it came from simulated data.\n",
    "\n",
    "**Unbiased** - An estimator that doesn't systematically over or underestimate the value of the parameter it is estimating\t\n",
    "\n",
    "**How much will the linear regression line expect to vary from sample to sample?**\n",
    "\n",
    "In the case of estimating a sample mean $\\hat{\\mu}$ from a number of points $n$, we get that the $Var(\\hat{\\mu}) = \\frac{\\sigma^2}{n}$ where $\\sigma$ is the standard distribution of the original set of $n$ points. \n",
    "\n",
    "The square root of this value is called the **standard error** and gives us a rough idea of how much the estimator will change from sample to sample.\n",
    "The standard errors of $\\beta_0$ and $\\beta_1$ are\n",
    "\t$$\tSE(\\hat{\\beta}_0)^2 = \\sigma^2 \\left[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n{\\left(x_i - \\bar{x} \\right)^2}} \\right] $$\n",
    "\t$$\tSE(\\hat{\\beta}_1)^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n{\\left(x_i - \\bar{x} \\right)^2}} $$\n",
    "    \n",
    "Knowing how to derive our standard error and assuming the errors are Gaussian we can generate a **confidence interval** based on a $t$-distribution. \n",
    "For instance, approximately 95\\% of all samples will be contained in the following interval: $$\\beta_1 \\pm 1.96 \\cdot SE(\\beta_1)$$\n",
    "\n",
    "If the standard error is large and the estimated value small then the estimator might not be significantly different than 0, meaning it statistically is insignificant. To test significance a hypothesis test can be done on any of the predictors. The hypothesis test is usually done to test whether the predictor is different than 0. \n",
    "\n",
    "The null hypothesis \n",
    "\t$$H_0: \\beta_1 = 0 $$\n",
    "is tested against the alternative\n",
    "$$H_a: \\beta_1 \\ne 0 $$\n",
    "\n",
    "To test this we find out how many standard errors our parameter is away from 0. \n",
    "\t$$t = \\frac{\\hat{\\beta_1}}{SE(\\hat{\\beta_1})}$$\n",
    "\n",
    "The $t$-distribution is then used to determine the percentage of time that a random value would fall beyond this t-statistic. This percentage is called the **$p$-value** and used as a measure of how extreme the results of your data are. \n",
    "The smaller the $p$-value the more extreme the results and the more likely they did not come from randomness.\n",
    "\n",
    "### Using the statsmodels api\n",
    "The excellent [statsmodels library](http://statsmodels.sourceforge.net/) integrates neatly with the pandas DataFrame to do statistical analysis. Some simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = smf.ols('Sales ~ TV', data=adv).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.612\n",
      "Model:                            OLS   Adj. R-squared:                  0.610\n",
      "Method:                 Least Squares   F-statistic:                     312.1\n",
      "Date:                Sat, 29 Mar 2025   Prob (F-statistic):           1.47e-42\n",
      "Time:                        12:12:42   Log-Likelihood:                -519.05\n",
      "No. Observations:                 200   AIC:                             1042.\n",
      "Df Residuals:                     198   BIC:                             1049.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.0326      0.458     15.360      0.000       6.130       7.935\n",
      "TV             0.0475      0.003     17.668      0.000       0.042       0.053\n",
      "==============================================================================\n",
      "Omnibus:                        0.531   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669\n",
      "Skew:                          -0.089   Prob(JB):                        0.716\n",
      "Kurtosis:                       2.779   Cond. No.                         338.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC --> Simulated Data\n",
    "\n",
    "BIC --> Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 29 Mar 2025</td> <th>  Prob (F-statistic):</th>  <td>0.00115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:14:44</td>     <th>  Log-Likelihood:    </th> <td> -608.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1221.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   1227.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   12.3514</td> <td>    0.621</td> <td>   19.876</td> <td> 0.000</td> <td>   11.126</td> <td>   13.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>    0.0547</td> <td>    0.017</td> <td>    3.300</td> <td> 0.001</td> <td>    0.022</td> <td>    0.087</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.231</td> <th>  Durbin-Watson:     </th> <td>   1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.044</td> <th>  Jarque-Bera (JB):  </th> <td>   5.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.330</td> <th>  Prob(JB):          </th> <td>  0.0645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.527</td> <th>  Cond. No.          </th> <td>    64.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Sales       & \\textbf{  R-squared:         } &     0.052   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.047   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     10.89   \\\\\n",
       "\\textbf{Date:}             & Sat, 29 Mar 2025 & \\textbf{  Prob (F-statistic):} &  0.00115    \\\\\n",
       "\\textbf{Time:}             &     12:14:44     & \\textbf{  Log-Likelihood:    } &   -608.34   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     1221.   \\\\\n",
       "\\textbf{Df Residuals:}     &         198      & \\textbf{  BIC:               } &     1227.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      12.3514  &        0.621     &    19.876  &         0.000        &       11.126    &       13.577     \\\\\n",
       "\\textbf{Newspaper} &       0.0547  &        0.017     &     3.300  &         0.001        &        0.022    &        0.087     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  6.231 & \\textbf{  Durbin-Watson:     } &    1.983  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.044 & \\textbf{  Jarque-Bera (JB):  } &    5.483  \\\\\n",
       "\\textbf{Skew:}          &  0.330 & \\textbf{  Prob(JB):          } &   0.0645  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.527 & \\textbf{  Cond. No.          } &     64.7  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.052\n",
       "Model:                            OLS   Adj. R-squared:                  0.047\n",
       "Method:                 Least Squares   F-statistic:                     10.89\n",
       "Date:                Sat, 29 Mar 2025   Prob (F-statistic):            0.00115\n",
       "Time:                        12:14:44   Log-Likelihood:                -608.34\n",
       "No. Observations:                 200   AIC:                             1221.\n",
       "Df Residuals:                     198   BIC:                             1227.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     12.3514      0.621     19.876      0.000      11.126      13.577\n",
       "Newspaper      0.0547      0.017      3.300      0.001       0.022       0.087\n",
       "==============================================================================\n",
       "Omnibus:                        6.231   Durbin-Watson:                   1.983\n",
       "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                5.483\n",
       "Skew:                           0.330   Prob(JB):                       0.0645\n",
       "Kurtosis:                       2.527   Cond. No.                         64.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression with newspaper\n",
    "results2 = smf.ols('Sales ~ Newspaper', data=adv).fit()\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   98.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 29 Mar 2025</td> <th>  Prob (F-statistic):</th> <td>4.35e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:14:52</td>     <th>  Log-Likelihood:    </th> <td> -573.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1151.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   1157.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    9.3116</td> <td>    0.563</td> <td>   16.542</td> <td> 0.000</td> <td>    8.202</td> <td>   10.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.2025</td> <td>    0.020</td> <td>    9.921</td> <td> 0.000</td> <td>    0.162</td> <td>    0.243</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.358</td> <th>  Durbin-Watson:     </th> <td>   1.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.764</td> <th>  Prob(JB):          </th> <td>1.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.544</td> <th>  Cond. No.          </th> <td>    51.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Sales       & \\textbf{  R-squared:         } &     0.332   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.329   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     98.42   \\\\\n",
       "\\textbf{Date:}             & Sat, 29 Mar 2025 & \\textbf{  Prob (F-statistic):} &  4.35e-19   \\\\\n",
       "\\textbf{Time:}             &     12:14:52     & \\textbf{  Log-Likelihood:    } &   -573.34   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     1151.   \\\\\n",
       "\\textbf{Df Residuals:}     &         198      & \\textbf{  BIC:               } &     1157.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       9.3116  &        0.563     &    16.542  &         0.000        &        8.202    &       10.422     \\\\\n",
       "\\textbf{Radio}     &       0.2025  &        0.020     &     9.921  &         0.000        &        0.162    &        0.243     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 19.358 & \\textbf{  Durbin-Watson:     } &    1.946  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   21.910  \\\\\n",
       "\\textbf{Skew:}          & -0.764 & \\textbf{  Prob(JB):          } & 1.75e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.544 & \\textbf{  Cond. No.          } &     51.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.332\n",
       "Model:                            OLS   Adj. R-squared:                  0.329\n",
       "Method:                 Least Squares   F-statistic:                     98.42\n",
       "Date:                Sat, 29 Mar 2025   Prob (F-statistic):           4.35e-19\n",
       "Time:                        12:14:52   Log-Likelihood:                -573.34\n",
       "No. Observations:                 200   AIC:                             1151.\n",
       "Df Residuals:                     198   BIC:                             1157.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      9.3116      0.563     16.542      0.000       8.202      10.422\n",
       "Radio          0.2025      0.020      9.921      0.000       0.162       0.243\n",
       "==============================================================================\n",
       "Omnibus:                       19.358   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.910\n",
       "Skew:                          -0.764   Prob(JB):                     1.75e-05\n",
       "Kurtosis:                       3.544   Cond. No.                         51.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3 = smf.ols('Sales ~ Radio', data=adv).fit()\n",
    "results3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "Instead of running a simple linear model for each predictor, a model can be built that incorporates all of the predictors. \n",
    "\n",
    "The MLR model is\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_p X_p + \\epsilon$$\n",
    "\n",
    "A few important questions in MLR:\n",
    "1. Is at least one of the predictors $X_1,X_2, \\ldots, X_p$ useful in predicting the response?\n",
    "2. Do all the predictors help to explain $Y$, or is only a subset of the predictors useful?\n",
    "3. How well does the model fit the data? **Use R$^2$ or RSE**\n",
    "\n",
    "4. Given a set of predictor values, what response value should we predict, and how accurate is our prediction? **Fit into the model. Use PI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: Test the hypothesis \n",
    "$$H_0 : \\beta_0 = \\beta_1 = \\beta_2 = \\cdots = \\beta_p =0$$\n",
    "vs\n",
    "\n",
    "$$H_a : \\textrm{at least one } \\beta_j \\neq 0$$\n",
    "\n",
    "An F test is performed to test for significance.\n",
    "$$ F = \\frac{(SST - SSE)/p}{SSE / (n - p - 1)}$$ \n",
    "\n",
    "or just use the P-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = smf.ols('Sales ~ TV + Newspaper + Radio', data=adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newspaper is least highly correlated with Sales\n",
    "# Its relatively high correlation to Radio could be the reason it was significant on its own and not\n",
    "# when Radio was also in the model\n",
    "adv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Sales ~ TV + Radio', data=adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2: Selecting a subset of a model\n",
    "In the above model, Newspaper does not appear to have a relationship with sales and hence would be a good candidate to drop from our model. But if the number of predictors were more, it might be troubling to manually fit many models and hand-select which variables to include in the model. Forward, backward and mixed selection processes can be used to find a better model. All of these selection models make their variable selection based on some statistic - AIC, BIC, Mallows CP, Adjusted R-squared\n",
    "\n",
    "* Forward - starts with an empty model and adds one variable at a time until the statistic is maximized\n",
    "* Backward - starts with a full model and removes one variable at a time\n",
    "* Mixed - starts empty and either removes or adds a variable at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical predictor variables\n",
    "Variables that are non-numeric or are numerical but represent categories are called categorical variables. Also called qualitative or factor variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('data/Credit.csv')\n",
    "credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit['Female'] = (credit.Gender == 'Female').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Balance ~ Female', data=credit).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing\n",
    "credit[credit['Female'] == 0]['Balance'].mean(), credit[credit['Female'] == 1]['Balance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Balance ~ Female + Age + Income', data=credit).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The broken assumptions of a linear model\n",
    "There are several assumptions that are used when fitting a linear model. \n",
    "* The errors are normally distributed and have constant variance\n",
    "* The errors are not correlated with one another\n",
    "* The predictor variables are independent. An increase in one won't result in an increase in another\n",
    "* The change in response for a one unit increase in X is the same no matter what the value of X\n",
    "\n",
    "# Challenging the linearity constraint through interaction effects\n",
    "In a linear regression with no interaction effects (no two predictors are multiplied together) and the assumption is that an increase in one unit in one variable will not have any effect on another variable. In many real world problems an increase in one variable might change the impact that another variable has on the response. To capture this in multiple regression, we multiply the predictors together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction model\n",
    "results = smf.ols('Sales ~ TV + Radio + TV * Radio', data=adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression is Still Linear\n",
    "Despite the fact that the regression line can be visibly non-linear the squaring predictor variables still means we are doing linear regression. The requirements for a regression to be 'linear' is to have it linear in the parameters. Heres a good link discussing the difference between linear and non-linear regression. http://blog.minitab.com/blog/adventures-in-statistics/what-is-the-difference-between-linear-and-nonlinear-equations-in-regression-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nonlinearity of data\n",
    "resid = adv['Sales'] - results.predict(adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like a non-random shape. data appears slightly non-linear though not too bad\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(results.predict(adv), resid)\n",
    "plt.ylim(-2, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab\n",
    "In the book, the lab focuses on performing a linear regression on the Boston dataset. We will do so using seaborn, statsmodels and scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv('data/boston.csv')\n",
    "boston.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='lstat', y='medv', data=boston);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statsmodels\n",
    "results = smf.ols('medv ~ lstat', data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at residuals\n",
    "# Yikes. lots of nonlinearity. Need a different model\n",
    "plt.scatter(results.fittedvalues, results.resid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns. No easy way to do this like in R\n",
    "# Mostly highly significant variables\n",
    "string_cols = ' + '.join(boston.columns[:-1])\n",
    "results = smf.ols('medv ~ {}'.format(string_cols), data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove age\n",
    "string_cols = ' + '.join(boston.columns[:-1].difference(['age']))\n",
    "results = smf.ols('medv ~ {}'.format(string_cols), data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction\n",
    "results = smf.ols('medv ~ lstat * age', data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction\n",
    "results = smf.ols('medv ~ lstat + np.power(lstat, 2)', data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = smf.ols('medv ~ lstat', data=boston).fit()\n",
    "results2 = smf.ols('medv ~ lstat + np.power(lstat, 2)', data=boston).fit()\n",
    "\n",
    "anova_lm(results1, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_lm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually compute F\n",
    "(results1.ssr - results2.ssr) / (results2.ssr / results2.df_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_lm(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carseats = pd.read_csv('data/carseats.csv')\n",
    "carseats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Sales ~ ShelveLoc + Price + Urban', data=carseats).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "There are 3 different null hypotheses for each of TV, Radio and Newspaper each testing whether there is a relationship from that variable to Sales given that the other two variables are held constant. From this model we can reject the null hypotheses that both TV and Radio have no correspondence with sales. We fail to reject the null hypotheses that Newspaper advertising is related to Sales.\n",
    "\n",
    "# 2\n",
    "KNN classification predicts as the category who has the highest frequency among it's k nearest neighbors. KNN regression predicts the mean of its nearest K neighbors.\n",
    "\n",
    "# 3\n",
    "a) iii is correct. Males will earn more than females GPA is high enough. Higher than 3.5 to be exact to wipe away the female advantage.  \n",
    "b) 50 + (20 * 4) + (.07 * 110) + (35 * 1) + (.01 * 110 * 4)  - (10 * 1 * 4) = 137.1  \n",
    "c) False, it all comes down to the standard error of the coefficient to determine significance. It could very well be the most significant factor.\n",
    "\n",
    "# 4\n",
    "a) For training data, the RSS always decreases as model complexity increases so the cubic model will have lower RSS.  \n",
    "b) For test data, the RSS for the linear model should do better as the cubic model will have fit noise and the true model is linear.  \n",
    "c) Cubic model. Same answer as a)  \n",
    "d) This would be impossible to know. It could go both ways as the true model is not known. Must compute RSS on test data in this case\n",
    "\n",
    "# 5\n",
    "Combining the first equation $\\hat{y_i} = x_i\\hat{\\beta}$ with (3.38) we get $$\\hat{y_i} = \\frac{x_i\\sum\\limits_{k=1}^n x_k y_k}{\\sum\\limits_{j=1}^nx_j^2}$$\n",
    "\n",
    "The $x_i$ outside of the summation is a constant and be distributed inside the summation. $$\\hat{y_i} = \\sum\\limits_{k=1}^n (\\frac{x_i x_k}{\\sum\\limits_{j=1}^nx_j^2})y_k$$\n",
    "\n",
    "$a_i$ is everything between the parentheses. $$a_i = \\frac{x_i x_k}{\\sum\\limits_{j=1}^nx_j^2}$$\n",
    "\n",
    "# 6\n",
    "Just rearrange the second equation in 3.4 and you have the equality \n",
    "# 7\n",
    "See image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/Chapter 3 - 7 proof.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('data/auto.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('mpg ~ horsepower', data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Yes there is strong evidence of a relationship between mpg and horsepower  \n",
    "ii) Just from the summary it is very strong as the t-statistic is -24 though there is still lots of variation left in the model with an r-squared of .6  \n",
    "iii) negative  \n",
    "iv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params['Intercept'] + results.params['horsepower'] * 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st, data, ss2 = summary_table(results, alpha=0.05)\n",
    "\n",
    "fittedvalues = data[:,2]\n",
    "predict_mean_se  = data[:,3]\n",
    "predict_mean_ci_low, predict_mean_ci_upp = data[:,4:6].T\n",
    "predict_ci_low, predict_ci_upp = data[:,6:8].T\n",
    "\n",
    "# wls cinv\n",
    "prstd, iv_l, iv_u = wls_prediction_std(results)\n",
    "\n",
    "# plot OLS\n",
    "cil, = plt.plot(auto['horsepower'], predict_ci_low, 'r--', lw=1, alpha=0.5)\n",
    "ciu, = plt.plot(auto['horsepower'], predict_ci_upp, 'r--', lw=1, alpha=0.5)\n",
    "mcil, = plt.plot(auto['horsepower'], predict_mean_ci_low, 'b--', lw=1, alpha=0.5)\n",
    "mciu, = plt.plot(auto['horsepower'], predict_mean_ci_upp, 'b--', lw=1, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.scatter(auto['horsepower'], auto['mpg']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to compute confidence or prediction interval given an x value\n",
    "def create_interval(ols_result, interval_type, alpha, x_values, conf_x):\n",
    "    if interval_type == 'confidence':\n",
    "        add_one = 0\n",
    "    elif interval_type == 'prediction':\n",
    "        add_one = 1\n",
    "    else:\n",
    "        print(\"Choose interval_type as confidence or prediction\")\n",
    "        return\n",
    "    n = len(x_values)\n",
    "    t_value = stats.t.ppf(1 - alpha / 2, df = n - 2)\n",
    "    sy = np.sqrt((ols_result.resid ** 2).sum() / (n - 2))\n",
    "    numerator = (conf_x - x_values.mean()) ** 2\n",
    "    denominator = ((x_values - x_values.mean()) ** 2).sum()\n",
    "    interval = t_value * sy * np.sqrt(add_one + 1 / n + numerator / denominator)\n",
    "    prediction = results.params[0] + results.params[1] * conf_x\n",
    "    return (prediction - interval, prediction + interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_interval(results, 'confidence', .05, auto['horsepower'], 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_interval(results, 'prediction', .05, auto['horsepower'], 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severe problems with the data\n",
    "plt.scatter(results.fittedvalues, results.resid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig = plot_leverage_resid2(results, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ ' + \" + \".join(auto.columns[1:-1])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(formula, data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) There is a clear relationship between predictor and response. F-stat is very high.  \n",
    "ii) displacement, weight, year, origin are statistically significant    \n",
    "iii) Its positive, so the higher the year the more the mpg    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) look at diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_influence = OLSInfluence(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# looks very similar to previous problem\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12,10))\n",
    "ax[0, 0].scatter(results.fittedvalues, results.resid)\n",
    "ax[0, 0].set_ylabel(\"Raw Residuals\")\n",
    "ax[1, 0].scatter(results.fittedvalues, results_influence.resid_studentized_external)\n",
    "ax[1, 0].set_ylabel(\"Studentized Residual\")\n",
    "sm.graphics.qqplot(results.resid / np.sqrt((results.resid ** 2).sum() / 390), line='45', ax=ax[0, 1])\n",
    "ax[1, 1].scatter(results_influence.resid_studentized_external ** 2, results_influence.influence);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most residuals fall within 3 standard deviations and the qqplot looks relatively good until the right tail where a few observations are above 3 standard deviations indicating outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point 13 has unusually large leverage\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig = plot_leverage_resid2(results, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Add interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ ' + \" + \".join(auto.columns[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_formula =  \" + \".join([comb[0] + \" * \" + comb[1] for comb in combinations(auto.columns[1:-1], 2)])\n",
    "interactions_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ ' + \" + \".join(auto.columns[1:-1])\n",
    "formula += ' + ' + interactions_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(formula, data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding all possible (7c2 = 21) interaction combination effects to the model only one of them is significant at the .01 level. Acceleration * origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add displacement squared to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula += ' + np.power(displacement, 2)'\n",
    "results = smf.ols(formula, data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of multicolinearity going on here\n",
    "results = smf.ols('mpg ~ displacement + origin + np.power(displacement, 2)', data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt of horsepower has higher r-squared than horsepower by itself\n",
    "results = smf.ols('mpg ~ np.sqrt(horsepower)', data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "ax1.scatter(auto['horsepower'], auto['mpg'])\n",
    "ax1.set_title(\"Horsepower vs MPG\")\n",
    "ax2.scatter(np.log(np.log(auto['horsepower'])), auto['mpg'])\n",
    "ax2.set_title(\"Log(Log(Horsepower)) vs MPG\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared increases a bit more with log-log-horsepower\n",
    "results = smf.ols('mpg ~ np.log(np.log((horsepower)))', data=auto).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Carseats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carseats = pd.read_csv('data/carseats.csv')\n",
    "carseats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Sales ~ Price + Urban + US', data=carseats).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only US and Price are statistically significant in our model. There is no difference whether someone is living in an urban area or not. Living in the US adds 1.2 to Sales up from 13 for outside of US. For every 1 unit increase in Price a corresponding .05 decrease in sales is seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# equations\n",
    "Ignoring Urban because its not significant.\n",
    "* In US: $Sales = 14.24 - .055 * Price$\n",
    "* Not in US: $Sales = 13.04 - .055 * Price$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Reject null for US and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) smaller model without urban\n",
    "results = smf.ols('Sales ~ Price + US', data=carseats).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Since urban is nearly completely random, there is almost no difference in the two models above. R-squared is low so lots of variance remains in the model  \n",
    "g) See table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't appear to be outliers\n",
    "plt.scatter(results.fittedvalues, results.resid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a few high leverage points above .025\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig = plot_leverage_resid2(results, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(100)\n",
    "y = 2 * x + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No constant. Highly signifcant predictor\n",
    "results = sm.OLS(y, x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x onto y. Same as above\n",
    "results = sm.OLS(x, y).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) The derived equation is symmetric to x and y, meaning you can replace x and y and the equation would be the exact same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(x, sm.add_constant(y)).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-statistic and t-stat is same with an intercept\n",
    "results = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12\n",
    "a) Using equation 3.38, the coefficients will be the same when $\\sum{y^2} = \\sum{x^2}$  \n",
    "b) Its very difficult to get the exact same coefficients. Any random pairing will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(100)\n",
    "y = x + np.random.randn(100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very close to a perfect line\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(y, x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients are just a little different\n",
    "results = sm.OLS(x, y).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) if x and y are the exact same (but in a different order) the coefficients for the model should be the same\n",
    "x = np.random.randn(100) * 5\n",
    "y = x.copy()\n",
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(x, y).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same coefficient!\n",
    "results = sm.OLS(y, x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(100)\n",
    "eps = np.random.randn(100) * .25\n",
    "y = -1 + .5 * x + eps # b0 = -1 and b1 = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient estimates are very close to actual\n",
    "results = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they are very close to one another\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, -1 + .5 * x, label ='pop')\n",
    "plt.plot(x, results.params[0] + results.params[1] * x, label = 'fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x squared is not significant\n",
    "x2 = np.column_stack((np.ones(100), x, x ** 2))\n",
    "results = sm.OLS(y, x2).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confidence intervals will shrink/expand with eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x1 = np.random.rand(100)\n",
    "x2 = .5 * x1 + np.random.rand(100) / 10\n",
    "y = 2 + 2 * x1 + .3 * x2 + np.random.randn(100)\n",
    "# regresion coeffs are 2, 2, .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very highly correlated. Only differ by random factor between 0 and .1\n",
    "np.corrcoef(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1, x2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprisingly both variables are not significant\n",
    "X = np.column_stack((np.ones(100), x1, x2))\n",
    "results = sm.OLS(y, X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones(100), x1))\n",
    "results = sm.OLS(y, X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones(100), x2))\n",
    "results = sm.OLS(y, X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since x1 and x2 are very highly correlated to one another it makes sense that when substituted in a linear model for one another a very similar r-squared would be achieved. The high collinearity is causing havoc with the model when both x1 and x2 are in the model. We know beforehand that each variable has a positive relationship with y and in the first model, x1 is positive and x2 is negative which is an impossibility. The standard errors for each predictor grow because of the collinearity which causes them not to be significant when they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_new = np.append(x1, .1)\n",
    "x2_new = np.append(x2, .8)\n",
    "y_new = np.append(y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((y_new, x1_new, x2_new))\n",
    "df_new = pd.DataFrame(X, columns=['y', 'x1', 'x2'])\n",
    "results = smf.ols('y ~ x2', data=df_new).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation goes way down with one point\n",
    "np.corrcoef(x1_new, x2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge outlier here\n",
    "plt.scatter(x1_new, x2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not an outlier in terms of residual, but very likely very influential\n",
    "plt.scatter(results.fittedvalues, results.resid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yup its unbelievably influential\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig = plot_leverage_resid2(results, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) simple linear regression for each predictor\n",
    "boston = pd.read_csv('data/boston.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below prints the confindence interval for each predictor in a simple linear regression\n",
    "# Nearly all the predictors have 95% confindence bands that don't include 0 meaning they rejecy the null hypothesis\n",
    "# the only predictors that fails to reject null: chas \n",
    "for col in boston.columns[1:]:\n",
    "    results = smf.ols('crim ~ {}'.format(col), data=boston).fit()\n",
    "    print(results.conf_int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'crim ~ ' + ' + '.join(boston.columns[1:])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All variables in model. Many are not significant now\n",
    "results = smf.ols(formula, data=boston).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all significant predictors\n",
    "results.tvalues[abs(results.tvalues) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all coefficients from multiple reression model\n",
    "multiple_linear_params = results.params.iloc[1:]\n",
    "\n",
    "simple_linear_params = pd.Series()\n",
    "for col in boston.columns[1:]:\n",
    "    results_slr = smf.ols('crim ~ {}'.format(col), data=boston).fit()\n",
    "    simple_linear_params = simple_linear_params.append(results_slr.params.loc[[col]])\n",
    "    \n",
    "both_models = pd.DataFrame({'simple': simple_linear_params, 'multiple':multiple_linear_params})\n",
    "both_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_models.plot.scatter('simple', 'multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are several variables raised to the power of 2 or 3 that are showing significance\n",
    "# but these need to be combined with other variables to assess their actual importance\n",
    "for col in boston.columns[1:]:\n",
    "    results = smf.ols('crim ~ {} + np.power({}, 2) + np.power({}, 3)'.format(col, col, col), data=boston).fit()\n",
    "    print(results.conf_int())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSc3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
