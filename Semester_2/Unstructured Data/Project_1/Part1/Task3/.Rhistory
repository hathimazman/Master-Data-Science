View(final_df)
df <- read.csv("D:/Downloads/test_SNA.csv", check.names = FALSE)
parse_peer_evaluation <- function(filepath, rater_id_col = "Matrix No", rank_prefix = "Rank your top 3") {
# Load file
df <- read.csv(filepath, check.names = FALSE)
# Ensure rater_id is present
df <- df %>% mutate(rater_id = as.character(df[[rater_id_col]]))
# Extract Likert columns (with names in square brackets)
likert_cols <- grep("\\[.*\\]", names(df), value = TRUE)
ratee_names <- str_extract(likert_cols, "(?<=\\[).+?(?=\\])")
names(df)[match(likert_cols, names(df))] <- ratee_names
# Pivot Likert scores to long format and compute C_ij
likert_long <- df %>%
select(rater_id, all_of(ratee_names)) %>%
pivot_longer(cols = -rater_id, names_to = "ratee_id", values_to = "score") %>%
mutate(score = as.numeric(str_extract(score, "^\\d+"))) %>%
group_by(rater_id, ratee_id) %>%
summarise(C_ij = sum(score, na.rm = TRUE), .groups = "drop")
# Extract Top 3 rank columns and assign rank points
rank_cols <- names(df)[grepl(rank_prefix, names(df))]
rank_weights <- rev(seq_along(rank_cols))  # 3, 2, 1
rank_long <- map2_dfr(rank_cols, rank_weights, function(col, pts) {
df %>%
select(rater_id, all_of(col)) %>%
rename(ratee_id = !!col) %>%
mutate(R_ij = pts)
})
# Combine into final dataframe
final_df <- likert_long %>%
left_join(rank_long, by = c("rater_id", "ratee_id")) %>%
mutate(R_ij = replace_na(R_ij, 0)) %>%
arrange(rater_id, desc(R_ij))
return(final_df)
}
# View first few rows
final <- parse_peer_evaluation("D:/Downloads/test_SNA.csv")
final
parse_peer_evaluation <- function(filepath, rater_id_col = "Matrix Number", rank_prefix = "Rank your top 3") {
# Load file
df <- read.csv(filepath, check.names = FALSE)
# Ensure rater_id is present
df <- df %>% mutate(rater_id = as.character(df[[rater_id_col]]))
# Extract Likert columns (with names in square brackets)
likert_cols <- grep("\\[.*\\]", names(df), value = TRUE)
ratee_names <- str_extract(likert_cols, "(?<=\\[).+?(?=\\])")
names(df)[match(likert_cols, names(df))] <- ratee_names
# Pivot Likert scores to long format and compute C_ij
likert_long <- df %>%
select(rater_id, all_of(ratee_names)) %>%
pivot_longer(cols = -rater_id, names_to = "ratee_id", values_to = "score") %>%
mutate(score = as.numeric(str_extract(score, "^\\d+"))) %>%
group_by(rater_id, ratee_id) %>%
summarise(C_ij = sum(score, na.rm = TRUE), .groups = "drop")
# Extract Top 3 rank columns and assign rank points
rank_cols <- names(df)[grepl(rank_prefix, names(df))]
rank_weights <- rev(seq_along(rank_cols))  # 3, 2, 1
rank_long <- map2_dfr(rank_cols, rank_weights, function(col, pts) {
df %>%
select(rater_id, all_of(col)) %>%
rename(ratee_id = !!col) %>%
mutate(R_ij = pts)
})
# Combine into final dataframe
final_df <- likert_long %>%
left_join(rank_long, by = c("rater_id", "ratee_id")) %>%
mutate(R_ij = replace_na(R_ij, 0)) %>%
arrange(rater_id, desc(R_ij))
return(final_df)
}
# View first few rows
final <- parse_peer_evaluation("D:/Downloads/test_SNA.csv")
final
# View first few rows
final <- parse_peer_evaluation("D:/Downloads/test_SNA.csv", "D:/Downloads/y1_mapping.csv")
# View first few rows
final <- parse_peer_evaluation("D:/Downloads/test_SNA.csv", "D:/Downloads/y1_mapping.csv")
df <- read.csv("D:/Downloads/test_SNA.csv", check.names = FALSE)
parse_peer_evaluation <- function(filepath, mapping_file,
rater_id_col = "Matrix Number",
rank_prefix = "Rank your top 3") {
library(tidyverse)
# Load evaluation and mapping data
df <- read.csv(filepath, check.names = FALSE)
mapping_df <- read.csv(mapping_file, check.names = FALSE)
colnames(mapping_df) <- c("ratee_matrix", "ratee_id")  # rename for merge clarity
# Ensure rater_id is present
df <- df %>% mutate(rater_id = as.character(df[[rater_id_col]]))
# Extract Likert columns
likert_cols <- grep("\\[.*\\]", names(df), value = TRUE)
ratee_names <- str_extract(likert_cols, "(?<=\\[).+?(?=\\])")
names(df)[match(likert_cols, names(df))] <- ratee_names
# Likert to long format
likert_long <- df %>%
select(rater_id, all_of(ratee_names)) %>%
pivot_longer(cols = -rater_id, names_to = "ratee_id", values_to = "score") %>%
mutate(score = as.numeric(str_extract(score, "^\\d+"))) %>%
group_by(rater_id, ratee_id) %>%
summarise(C_ij = sum(score, na.rm = TRUE), .groups = "drop")
# Top 3 ranking
rank_cols <- names(df)[grepl(rank_prefix, names(df))]
rank_weights <- rev(seq_along(rank_cols))  # 3, 2, 1
rank_long <- map2_dfr(rank_cols, rank_weights, function(col, pts) {
df %>%
select(rater_id, all_of(col)) %>%
rename(ratee_id = !!col) %>%
mutate(R_ij = pts)
})
# Merge both scores
final_df <- likert_long %>%
left_join(rank_long, by = c("rater_id", "ratee_id")) %>%
mutate(R_ij = replace_na(R_ij, 0)) %>%
left_join(mapping_df, by = "ratee_id") %>%
mutate(ratee_id = coalesce(ratee_matrix, ratee_id)) %>%
select(rater_id, ratee_id, C_ij, R_ij) %>%
arrange(rater_id, desc(R_ij))
return(final_df)
}
parse_peer_evaluation <- function(filepath, mapping_file,
rater_id_col = "Matrix Number",
rank_prefix = "Rank your top 3") {
# Load evaluation and mapping data
df <- read.csv(filepath, check.names = FALSE)
mapping_df <- read.csv(mapping_file, check.names = FALSE)
colnames(mapping_df) <- c("ratee_matrix", "ratee_id")  # rename for merge clarity
# Ensure rater_id is present
df <- df %>% mutate(rater_id = as.character(df[[rater_id_col]]))
# Extract Likert columns
likert_cols <- grep("\\[.*\\]", names(df), value = TRUE)
ratee_names <- str_extract(likert_cols, "(?<=\\[).+?(?=\\])")
names(df)[match(likert_cols, names(df))] <- ratee_names
# Likert to long format
likert_long <- df %>%
select(rater_id, all_of(ratee_names)) %>%
pivot_longer(cols = -rater_id, names_to = "ratee_id", values_to = "score") %>%
mutate(score = as.numeric(str_extract(score, "^\\d+"))) %>%
group_by(rater_id, ratee_id) %>%
summarise(C_ij = sum(score, na.rm = TRUE), .groups = "drop")
# Top 3 ranking
rank_cols <- names(df)[grepl(rank_prefix, names(df))]
rank_weights <- rev(seq_along(rank_cols))  # 3, 2, 1
rank_long <- map2_dfr(rank_cols, rank_weights, function(col, pts) {
df %>%
select(rater_id, all_of(col)) %>%
rename(ratee_id = !!col) %>%
mutate(R_ij = pts)
})
# Merge both scores
final_df <- likert_long %>%
left_join(rank_long, by = c("rater_id", "ratee_id")) %>%
mutate(R_ij = replace_na(R_ij, 0)) %>%
left_join(mapping_df, by = "ratee_id") %>%
mutate(ratee_id = coalesce(ratee_matrix, ratee_id)) %>%
select(rater_id, ratee_id, C_ij, R_ij) %>%
arrange(rater_id, desc(R_ij))
return(final_df)
}
# View first few rows
final <- parse_peer_evaluation("D:/Downloads/test_SNA.csv", "D:/Downloads/y1_mapping.csv")
final
View(final)
library(httr)
library(rvest)
library(dplyr)
library(XML)
library(tidyverse)
newborn_pages <- paste0("https://www.amazon.com/s?k=newborn+diapers&page=",1:3)
diapers_pages <- paste0("https://www.amazon.com/s?k=diapers&page=",1:3)
# Function to extract titles from a single page
extract_details <- function(page_url) {
page <- read_html(page_url)
# Extract product titles using the h2 tag with specific classes
title_nodes <- html_nodes(page, 'h2.a-size-base-plus.a-spacing-none.a-color-base.a-text-normal span')
price_nodes <- html_nodes(page, '.a-price-whole')
delivery_nodes <- html_nodes(page, 'div[data-cy="delivery-recipe"] span.a-text-bold')
# Get the text content
titles <- html_text(title_nodes)
prices <- html_text(price_nodes)
deliveries <- html_text(delivery_nodes)
# Pad shorter vector with NA
max_len <- max(length(titles), length(prices), length(deliveries))
length(titles) <- max_len
length(prices) <- max_len
length(deliveries) <- max_len
# Combine into dataframe
df <- data.frame(Title = titles, Price = prices, Deliveries = deliveries,stringsAsFactors = FALSE)
return(df)
}
newborn <- do.call("rbind", lapply(newborn_pages, extract_details))
diapers <- do.call("rbind", lapply(diapers_pages, extract_details))
newborn_processed <- newborn %>%
mutate(
Price = as.numeric(Price),
DeliveryDateParsed = as.Date(
paste(Deliveries, format(Sys.Date(), "%Y")),
format = "%a, %b %d %Y"
),
DeliveryDuration = as.numeric(DeliveryDateParsed - Sys.Date())
) %>%
drop_na(Title, Price, DeliveryDateParsed) %>%
select(-Deliveries)
newborn_processed
mean(newborn_processed$DeliveryDuration)
diapers_processed <- diapers %>%
mutate(
Price = as.numeric(Price),
DeliveryDateParsed = as.Date(
paste(Deliveries, format(Sys.Date(), "%Y")),
format = "%a, %b %d %Y"
),
DeliveryDuration = as.numeric(DeliveryDateParsed - Sys.Date())
) %>%
drop_na(Title, Price, DeliveryDateParsed) %>%
select(-Deliveries)
diapers_processed
mean(diapers_processed$DeliveryDuration)
brands <- c("Huggies", "Pampers", "Mama Bear")
# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})
# 2. Calculate mean price per brand
brand_price <- function(brand) {
# Extract titles and prices matching the brand
matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
brand_prices <- information$Price[matching]
# Clean price and convert to numeric
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
# Return mean price if available
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
# 3. Combine results into data frame
diapers_df <- data.frame(
Brand = brands,
Count = brand_counts,
Mean_Price = sapply(brands, brand_price),
stringsAsFactors = FALSE
)
print(diapers_df)
brands <- c("Huggies", "Pampers", "Mama Bear")
# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})
# 2. Calculate mean price per brand
brand_price <- function(brand) {
# Extract titles and prices matching the brand
matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
brand_prices <- information$Price[matching]
# Clean price and convert to numeric
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
# Return mean price if available
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
# 3. Combine results into data frame
diapers_df <- data.frame(
Brand = brands,
Count = brand_counts,
Mean_Price = sapply(brands, brand_price),
stringsAsFactors = FALSE
)
print(diapers_df)
brands <- c("Huggies", "Pampers", "Mama Bear")
# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})
# 2. Calculate mean price per brand
brand_price <- function(brand) {
# Extract titles and prices matching the brand
matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
brand_prices <- diapers_processed$Price[matching]
# Clean price and convert to numeric
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
# Return mean price if available
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
# 3. Combine results into data frame
diapers_df <- data.frame(
Brand = brands,
Count = brand_counts,
Mean_Price = sapply(brands, brand_price),
stringsAsFactors = FALSE
)
print(diapers_df)
newborn_brand_counts <- sapply(brands, function(brand) {
pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
sum(str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE)))
})
newborn_brand_price <- function(brand) {
pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
matching <- str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE))
brand_prices <- newborn_processed$Price[matching]
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
newborn_df <- data.frame(
Brand = brands,
Count = newborn_brand_counts,
Mean_Price = sapply(brands, newborn_brand_price),
stringsAsFactors = FALSE
)
print(newborn_df)
brands <- c("Huggies", "Pampers", "Mama Bear", "Dryper", "Hello Bello", "Luvs")
# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})
# 2. Calculate mean price per brand
brand_price <- function(brand) {
# Extract titles and prices matching the brand
matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
brand_prices <- diapers_processed$Price[matching]
# Clean price and convert to numeric
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
# Return mean price if available
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
# 3. Combine results into data frame
diapers_df <- data.frame(
Brand = brands,
Count = brand_counts,
Mean_Price = sapply(brands, brand_price),
stringsAsFactors = FALSE
)
print(diapers_df)
brands <- c("Huggies", "Pampers", "Mama Bear", "Dyper", "Hello Bello", "Luvs")
# 1. Count matches for each brand (case-insensitive)
brand_counts <- sapply(brands, function(brand) {
sum(str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE)))
})
# 2. Calculate mean price per brand
brand_price <- function(brand) {
# Extract titles and prices matching the brand
matching <- str_detect(diapers_processed$Title, regex(brand, ignore_case = TRUE))
brand_prices <- diapers_processed$Price[matching]
# Clean price and convert to numeric
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
# Return mean price if available
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
# 3. Combine results into data frame
diapers_df <- data.frame(
Brand = brands,
Count = brand_counts,
Mean_Price = sapply(brands, brand_price),
stringsAsFactors = FALSE
)
print(diapers_df)
newborn_brand_counts <- sapply(brands, function(brand) {
pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
sum(str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE)))
})
newborn_brand_price <- function(brand) {
pattern <- paste0("(?=.*newborn)(?=.*", brand, ")")
matching <- str_detect(newborn_processed$Title, regex(pattern, ignore_case = TRUE))
brand_prices <- newborn_processed$Price[matching]
brand_prices <- as.numeric(gsub(",", "", brand_prices))
brand_prices <- na.omit(brand_prices)
if (length(brand_prices) == 0) {
return(NA)
} else {
return(mean(brand_prices))
}
}
newborn_df <- data.frame(
Brand = brands,
Count = newborn_brand_counts,
Mean_Price = sapply(brands, newborn_brand_price),
stringsAsFactors = FALSE
)
print(newborn_df)
talalusakit <- readLines("dataset/talalusakit.csv")
bohemian <- readLines("dataset/bohemianrhapsody.csv")
jatuhsuka <- readLines("dataset/jatuhsuka.csv")
uptown <- readLines("dataset/uptownfunk.csv")
mantera <- readLines("dataset/mantera.csv")
library(tidyverse)
library(tm)
library(SnowballC)
library(textstem)
library(wordcloud2)
talalusakit <- readLines("dataset/talalusakit.csv")
bohemian <- readLines("dataset/bohemianrhapsody.csv")
jatuhsuka <- readLines("dataset/jatuhsuka.csv")
uptown <- readLines("dataset/uptownfunk.csv")
mantera <- readLines("dataset/mantera.csv")
setwd("D:/Github Repo/Master-Data-Science/Semester_2/Unstructured Data/Project_1/Part1/Task3")
talalusakit <- readLines("dataset/talalusakit.csv")
bohemian <- readLines("dataset/bohemianrhapsody.csv")
jatuhsuka <- readLines("dataset/jatuhsuka.csv")
uptown <- readLines("dataset/uptownfunk.csv")
mantera <- readLines("dataset/mantera.csv")
whenwewereyoung <- readLines("dataset/whenwewereyoung.csv")
bohemian <- readLines("dataset/bohemianrhapsody.csv")
jatuhsuka <- readLines("dataset/jatuhsuka.csv")
uptown <- readLines("dataset/uptownfunk.csv")
mantera <- readLines("dataset/mantera.csv")
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ", x))
})
process_wordcloud <- function(lyrics, language) {
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- Corpus(VectorSource(lyrics))
docs <- tm_map(docs, toSpace, "-")
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
if (language == "en") {
docs <- tm_map(docs, removeWords, stopwords("english"))
}
dtm <- DocumentTermMatrix(docs)
freq <- colSums(as.matrix(dtm))
wf <- data.frame(TERM = names(freq), FREQ = freq)
wf <- wf %>%
arrange(desc(FREQ)) %>%
filter(FREQ >= 5)
print(wordcloud2(wf))
return(wf)
}
process_wordcloud(whenwewereyoung, "en")
process_wordcloud(whenwewereyoung, "en")
process_wordcloud(bohemian)
process_wordcloud(bohemian, "en")
process_wordcloud(uptown)
process_wordcloud(uptown, "en")
process_wordcloud(jatuhsuka, "ind")
process_wordcloud(mantera, "bm")
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ", x))
})
process_wordcloud <- function(lyrics, language) {
stopwords_bm <- c(
"ada", "adalah", "agak", "agaknya", "akan", "aku", "amat", "anda", "apa", "apakah", "atas", "atau",
"bagai", "bagaimana", "bahawa", "bahkan", "banyak", "beberapa", "bagi", "begitu", "belum", "bila", "boleh",
"bersama", "bolehkah", "bukan", "cuma", "dalam", "dan", "dari", "dahulu", "dengan", "di", "dia", "dialah",
"jika", "jadi", "juga", "jangan", "kamu", "kami", "kata", "ke", "ketika", "kerana", "kepada", "kita", "kalau",
"lagi", "lalu", "lebih", "mahupun", "maka", "mahu", "mana", "masih", "me", "menjadi", "mungkin", "mesti",
"namun", "nya", "orang", "oleh", "pada", "pun", "pernah", "saja", "sangat", "satu", "saya", "sendiri", "sejak",
"serta", "sini", "situ", "suatu", "sudah", "semua", "sedang", "sahaja", "tetapi", "telah", "tanpa", "tidak",
"tiap", "tiap-tiap", "untuk", "yang"
)
stopwords_ind <- c(
"ada", "adalah", "adakah", "akan", "aku", "amat", "anda", "apa", "apakah", "atau", "bagi", "bahwa",
"banyak", "beberapa", "bila", "begitu", "belum", "bisa", "bukan", "cara", "dalam", "dan", "dari",
"dengan", "dia", "dimana", "dulu", "guna", "harus", "hingga", "ini", "itu", "jadi", "jika", "juga",
"karena", "kami", "kamu", "kan", "ke", "ketika", "kita", "lagi", "lalu", "lebih", "maka", "masih",
"mau", "melalui", "mereka", "meskipun", "mesti", "mungkin", "milik", "namun", "nanti", "nya", "oleh",
"pada", "pasti", "paling", "perlu", "pernah", "pun", "punya", "saja", "sangat", "salah", "sama", "saya",
"sendiri", "sejak", "serta", "sesudah", "setiap", "sudah", "supaya", "sedang", "selalu", "tentang",
"tidak", "tanpa", "telah", "untuk", "yang"
)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- Corpus(VectorSource(lyrics))
docs <- tm_map(docs, toSpace, "-")
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
if (language == "en") {
docs <- tm_map(docs, removeWords, stopwords("english"))
} else if (language == "bm") {
docs <- tm_map(docs, removeWords, stopwords_bm)
} else if (language == "ind") {
docs <- tm_map(docs, removeWords, stopwords_ind)
}
dtm <- DocumentTermMatrix(docs)
freq <- colSums(as.matrix(dtm))
wf <- data.frame(TERM = names(freq), FREQ = freq)
wf <- wf %>%
arrange(desc(FREQ)) %>%
filter(FREQ >= 5)
print(wordcloud2(wf))
return(wf)
}
process_wordcloud(whenwewereyoung, "en")
process_wordcloud(bohemian, "en")
process_wordcloud(uptown, "en")
process_wordcloud(jatuhsuka, "ind")
process_wordcloud(mantera, "bm")
bagaimana <- readLines("dataset/bagaimana.csv")
process_wordcloud(bagaimana, "ind")
