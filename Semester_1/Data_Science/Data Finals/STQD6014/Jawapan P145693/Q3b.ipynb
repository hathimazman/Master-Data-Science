{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3093a9f3-93c1-4f3b-aaca-d2fe3e648009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC04\\Desktop\\stq6014_data sains_sem1\\Data\n",
      "C:\\Users\\PC04\\Desktop\\stq6014_data sains_sem1\\Data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Current dir\n",
    "os.chdir(\"C:/Users/PC04/Desktop/stq6014_data sains_sem1/Data\")\n",
    "#\"C:\\Users\\PC04\\Desktop\\stq6014_data sains_sem1\\Data\"\n",
    "print(os.getcwd())  # Current dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fff6f009-78fb-46b2-9721-098cd23ede7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text read successfully!\n",
      "First 300 characters of the combined file:\n",
      " ﻿the project gutenberg ebook of alice in wonderland\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg lice\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read and merge all three files\n",
    "file_names = [\"01Alice_Wonderland.txt\", \"02Little_Wizard_Oz.txt\", \"03Casebook_Sherlock_Holmes.txt\"]\n",
    "combined_text = \"\"\n",
    "\n",
    "for file in file_names:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        combined_text += f.read().lower() + \" \"  # Convert text to lowercase\n",
    "\n",
    "# Print first 300 characters\n",
    "print(\"Combined text read successfully!\")\n",
    "print(\"First 300 characters of the combined file:\\n\", combined_text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb1ee80e-1603-47ff-8d39-0d22a987b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Preprocessed Text without Stop Words (First 50 Words)\n",
      "['casebooksherlockholmestxt']\n"
     ]
    }
   ],
   "source": [
    " # Step 2: Preprocess the text\n",
    "def preprocess_text(file):\n",
    "    # Convert text to lowercase\n",
    "    file= file.lower()\n",
    "    \n",
    "    # Remove punctuation manually\n",
    "    punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    for char in punctuation:\n",
    "         file =  file.replace(char, '')\n",
    "\n",
    "    # Remove numbers manually\n",
    "    numbers = '0123456789'\n",
    "    for num in numbers:\n",
    "         file =  file.replace(num, '')\n",
    "\n",
    "    # Split text into words\n",
    "    words =  file.split()\n",
    "    return words\n",
    "\n",
    "# Define stop words\n",
    "stop_words = ['the', 'and', 'is', 'in', 'to', 'with', 'a', 'of', 'for', 'on', 'it', 'this', 'that', 'you', 'i', 'he', 'she', 'we', 'they', 'as', 'at', 'by', 'an', 'be', 'not']\n",
    "\n",
    "# Perform preprocessing and remove stop words\n",
    "words = preprocess_text( file)\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(\"\\nStep 2: Preprocessed Text without Stop Words (First 50 Words)\")\n",
    "print(filtered_words[:50])  # Display the first 50 words for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24d1857f-5917-47d0-99d6-612d969d5c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special cases removed!\n",
      "First 300 characters after cleaning:\n",
      " ﻿the project gutenberg ebook of alice in wonderland\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg lice\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Remove emails\n",
    "combined_text = re.sub(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b\", \" \", combined_text)\n",
    "\n",
    "# Remove floating point numbers\n",
    "combined_text = re.sub(r\"\\b\\d+\\.\\d+\\b\", \" \", combined_text)\n",
    "\n",
    "# Remove dates\n",
    "combined_text = re.sub(r\"\\b\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}\\b\", \" \", combined_text)\n",
    "\n",
    "# Remove money values\n",
    "combined_text = re.sub(r\"\\$\\d{1,3}(,\\d{3})*(\\.\\d+)?\", \" \", combined_text)\n",
    "\n",
    "print(\"Special cases removed!\")\n",
    "print(\"First 300 characters after cleaning:\\n\", combined_text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "727980a8-e979-41d4-b027-60c0e7bfb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords removed! Total words after cleaning: 75218\n"
     ]
    }
   ],
   "source": [
    "# List of stopwords\n",
    "stopwords = {\"the\", \"is\", \"in\", \"and\", \"of\", \"to\", \"a\", \"for\", \"on\", \"with\", \"as\", \"at\", \"by\",\n",
    "             \"an\", \"be\", \"this\", \"that\", \"it\", \"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"from\", \"or\",\n",
    "             \"was\", \"were\", \"been\", \"has\", \"had\", \"have\", \"am\", \"are\", \"not\", \"but\", \"so\", \"can\", \"could\"}\n",
    "\n",
    "# Split words and remove stopwords\n",
    "words = combined_text.split()\n",
    "filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "print(\"Stopwords removed! Total words after cleaning:\", len(filtered_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "177922b8-7836-46c7-a755-bdcf401a5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Word Frequencies (First 20 Words)\n",
      "casebooksherlockholmestxt: 1\n"
     ]
    }
   ],
   "source": [
    " #Step 3: Count word frequencies\n",
    "word_freq = {}\n",
    "for word in words:\n",
    "    if word in word_freq:\n",
    "        word_freq[word] += 1\n",
    "    else:\n",
    "        word_freq[word] = 1\n",
    "\n",
    "print(\"\\nStep 3: Word Frequencies (First 20 Words)\")\n",
    "for i, (word, freq) in enumerate(word_freq.items()):\n",
    "    if i < 20:\n",
    "        print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43cb0c-9352-4d53-9ce9-adfef1858615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
