library(dplyr)
library(lubridate)
library(stringr)
library(DataCombine)
library(corrgram)
library(psych)

========================
getwd()
setwd(dir = "C:/Users/PC03/Documents")
datch1= read.csv(file.choose())
head(datch1,10)
str(datch1)

library(dplyr)

extracted_rows = filter(datch1, registered == 0,
				season == 1 | season == 2)
dim(extracted_rows)

using_membership = filter(datch1, registered == 0, season %in% c(1,2))
identical(extracted_rows, using_membership)

add_revenue = mutate(extracted_rows, revenue = casual*5)

head(add_revenue,10)
head(extracted_rows,10)

grouped = group_by(add_revenue,season)
head(grouped,10)
grouped
report = summarise(grouped, Casual = sum(casual), Revenue = sum(revenue))
report

write.csv(report, "revenue_report.csv", row.names = FALSE)
write.table(report, "revenue_report.txt", row.names = FALSE)

# -----------------------------------------------------------------------

bike = read.csv(file.choose())
head(bike,10)
str(bike)

table(is.na(bike))

bad_data = str_subset(bike$humidity, '[a-z A-Z]')
bad_data
location = str_detect(bike$humidity, bad_data)
bike[,location]

bike$humidity = str_replace_all(bike$humidity, bad_data, "61")
table(is.na(bike))
str(bike)
bike$humidity = as.numeric(bike$humidity)
library(lubridate)

bike$holiday = factor(bike$holiday, levels = c(0,1),
                        labels = c("no","yes"))
bike$workingday = factor(bike$workingday, levels = c(0,1),
                        labels = c("no","yes"))
bike$weather = factor(bike$weather, levels = c(1,2,3,4),
                        labels = c("clr_part_cloud",
                                    "mist_cloudy",
                                    "lt_rain_snow",
                                    "hcy_rain_snow"),
                        ordered = TRUE)
bike$season = factor(bike$season, levels = c(1,2,3,4),
                        labels = c("spring","summer",
                                    "fall","winter"),
                        ordered = TRUE)
bike$datetime = mdy_hm(bike$datetime)

unique(bike$sources)
bike$sources = tolower(bike$sources)
bike$sources = str_trim(bike$sources)
library(stringr)
na_loc = is.na(bike$sources)
na_loc
bike$sources[na_loc] = "unknown"

library(DataCombine)
install.packages("DataCombine")
web_sites = "www.[\w]*.[\w]*((.[a-z]*)*)?"
current = unique(str_subset(bike$sources, web_sites))
current
replace = rep("web", length(current))
replace
replacements = data.frame(from = current, to = replace)
replacements
bike = FindReplace(data = bike, Var = "sources", replacements, from = "from", to = "to", exact = FALSE)
unique(bike$sources)
bike$sources = as.factor(bike$sources)
str(bike$sources)

====================================================================
getwd()

marketing = read.csv("Sem 1/Business Analytics/Ch3_marketing.csv", stringsAsFactors = TRUE)
str(marketing)

marketing$pop_density = factor(marketing$pop_density,
                                ordered = TRUE,
                                levels = c('Low','Medium','High'))

summary(marketing$pop_density)
summary(marketing$google_adwords)
sd(marketing$google_adwords)
var(marketing$google_adwords)

summary2 = function(x) {
    results = c(summary(x),'StdDev.' = sd(x),'Var.' = var(x), 'IQR' = IQR(x))
    return(results)
}
summary2(marketing$google_adwords)
quantile(marketing$google_adwords, 0.25)

summary3 = function(x) {
    results = c('Min' = min(x), 
                'Q1' = quantile(x, 0.25), 
                'Median' = median(x), 
                'Mean' = mean(x), 
                'Q3' = quantile(x, 0.75), 
                'Max' = max(x), 
                'StdDev' = sd(x), 
                'Var' = var(x),
                'IQR' = IQR(x))
    results
}
summary3(marketing$google_adwords)
summary2((marketing$facebook))

summary(marketing$pop_density)
layout(matrix(1:4,ncol = 2)) # or par(mfrow = c(2,2))
par(mfrow = c(2,2))
boxplot(marketing$google_adwords, ylab = 'Expenditures', main = 'Google')
hist(marketing$google_adwords, main = 'Google', xlab = NULL)
boxplot(marketing$twitter, ylab = 'Expenditures', col = 'blue', main = 'Twitter')
hist(marketing$twitter, col = 'blue', main = 'Twitter', xlab = NULL)
# plot(marketing$pop_density)

summary(marketing)
marketing$emp_factor = cut(marketing$employees , 2)
marketing$emp_factor
# marketing$emp_factor = as.factor(marketing$emp_factor, labels = c('Low Employee', 'High Employee'))

levels(marketing$emp_factor) = c('Low Employee', 'High Employee')
table1 = table(marketing$pop_density,marketing$emp_factor)

layout(matrix(3:1, ncol = 1))
par(mfrow = c(3,1))
mosaicplot(table1, 
            col=c('gray','black'), 
            main = 'Factor / Factor')
boxplot(marketing$marketing_total ~ marketing$pop_density, 
        main = 'Factor / Numeric')
plot(marketing$revenues, marketing$google_adwords,
    main = 'Numeric / Numeric')

cor(marketing$google_adwords,marketing$revenues)
cor(marketing$google_adwords, marketing$facebook)

cor.test(marketing$google_adwords, marketing$revenues)

cor_test = function(x,y) {
    results = cor.test(x,y)
    output = c(#'Data' = results$data.name, 
                'Correlation Coefficient' = results$estimate, 
                'p-value' = results$p.value)
    output
}

a = cor_test(marketing$google_adwords, marketing$revenues)
str(a)
colnames(marketing)
for (item in colnames(marketing)) {
    for(item2 in colnames(marketing)) {
        if(is.numeric(marketing[[item]]) & is.numeric(marketing[[item2]])) {
            result = cor_test(marketing[[item]],marketing[[item2]])
            print(result)
        }
    }
}
# is.numeric(marketing$google_adwords)
for(item in colnames(marketing)) {
    for(item2 in colnames(marketing)) {
        print(marketing[[item]])
        print(item2)
    }
}

cor(marketing[,1:6])
library(psych)
install.packages('psych')
library(psych)
corr.test(marketing[,1:6])
pairs(marketing)

#install.packages('corrgram')
library(corrgram)
layout(matrix(1:2, ncol=2))
corrgram(marketing,order=TRUE,
         main = "Correlogram of Marketing Data Ordered",
         lower.panel = panel.shade,
         upper.panel = panel.ellipse,
         diag.panel = panel.minmax,
         text.panel = panel.txt)

corrgram(marketing,order=FALSE,
         main = "Correlogram of Marketing Data Unordered",
         lower.panel = panel.conf,
         upper.panel = panel.shade,
         diag.panel = panel.minmax,
         text.panel = panel.txt)

====================================================================
adverts = read.csv("D:/Data_Analyst/MSc Data Science/Sem 1/Business Analytics/Ch4_marketing.csv")
head(adverts, 10)

str(adverts)
summary(adverts)
?lm

layout(matrix(2:1, ncol=2))
pairs(adverts)
plot(adverts$marketing_total, adverts$revenues, ylab="Revenues",xlab="Marketing Total", main="Revenues and Marketing Total")

m1 = lm(revenues ~ marketing_total, data = adverts)
m1

str(m1)

yhat_model = m1$fitted.values
beta0_model = m1$coefficients[1]
beta1_model = m1$coefficients[2]
Res_model = m1$residuals

yhat_manual = beta0_model + (beta1_model*adverts$marketing_total)
Res_manual = adverts$revenues - yhat_manual

compiled = data.frame(
  "yhat_model" = yhat_model,
  "yhat_manual" = yhat_manual,
  "Diff_yhat" = sum(round(yhat_manual,8)) - sum(round(yhat_model,8)),
  "Res_model" = Res_model,
  "Res_manual" = Res_manual
)

head(compiled,10)
str(compiled)
sum(round(yhat_manual,8)) - sum(round(yhat_model,8))
sum(Res_manual) - sum(Res_model)

par(mfrow = c(2,1))
hist(m1$residuals, xlab = "Residuals", col = 'grey', main = "Histogram of Residuals")
qqnorm(m1$residuals, main = "QQPlot of Residuals")
qqline(m1$residuals)

plot(m1$fitted.values, m1$residuals, ylab = "Residuals", xlab = 'Fitted Values', main = "Residual Distribution")
abline(h = 0,lwd=3); abline(h = c(-5,5), lwd=3,lty=3)
# ?abline

summary(m1)

newdata = data.frame(marketing_total = 460)
predict.lm(m1, newdata, interval = 'predict')
?predict.lm

predict.lm(m1,newdata, level = 0.99, interval = 'predict')

newdata = data.frame(marketing_total = c(450,460,470))
predict.lm(m1, newdata, interval = 'predict')
predict.lm(m1, newdata, interval = 'confidence')

?confint
library(dplyr)
market_sample = sample_frac(adverts, 0.3, replace = FALSE)



